{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi armed bandit test model:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiArmedBanditUCB1:\n",
    "#     def _init_(self, num_arms, data):\n",
    "#         self.num_arms = num_arms\n",
    "#         self.data = data\n",
    "#         self.action_values = np.zeros(num_arms)\n",
    "#         self.num_actions_taken = np.zeros(num_arms)\n",
    "#         self.total_reward = 0\n",
    "\n",
    "#     def choose_action(self, time_step):\n",
    "#         c = 2  # Exploration parameter\n",
    "#         for arm in range(self.num_arms):\n",
    "#             if self.num_actions_taken[arm] == 0:\n",
    "#                 return arm\n",
    "#         ucb_values = self.action_values + c * np.sqrt(np.log(time_step) / self.num_actions_taken)\n",
    "#         action = np.argmax(ucb_values)\n",
    "#         return action\n",
    "\n",
    "#     def update_action_value(self, action, reward):\n",
    "#         self.num_actions_taken[action] += 1\n",
    "#         self.total_reward += reward\n",
    "#         self.action_values[action] += (reward - self.action_values[action]) / self.num_actions_taken[action]\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming you have a dataset with the number of arms and the rewards for each arm\n",
    "# num_arms = len(data)\n",
    "# bandit = MultiArmedBanditUCB1(num_arms, data)\n",
    "\n",
    "# time_step = 0\n",
    "# total_time_steps = 1000  # Adjust as needed\n",
    "# while time_step < total_time_steps:\n",
    "#     action = bandit.choose_action(time_step + 1)\n",
    "#     reward = data[action]  # Assuming data contains rewards for each arm\n",
    "#     bandit.update_action_value(action, reward)\n",
    "#     time_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_data_pre_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display.max_characters = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_english</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>type_of</th>\n",
       "      <th>total_episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>studios</th>\n",
       "      <th>genres</th>\n",
       "      <th>demographic</th>\n",
       "      <th>duration_per_ep</th>\n",
       "      <th>rating</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>favorites</th>\n",
       "      <th>aired</th>\n",
       "      <th>source</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>plan_to_watch</th>\n",
       "      <th>total</th>\n",
       "      <th>scored_10_by</th>\n",
       "      <th>scored_9_by</th>\n",
       "      <th>scored_8_by</th>\n",
       "      <th>scored_7_by</th>\n",
       "      <th>scored_6_by</th>\n",
       "      <th>scored_5_by</th>\n",
       "      <th>scored_4_by</th>\n",
       "      <th>scored_3_by</th>\n",
       "      <th>scored_2_by</th>\n",
       "      <th>scored_1_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frieren: Beyond Journey's End</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>9.39</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>665374</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>Frieren at the Funeral</td>\n",
       "      <td>TV</td>\n",
       "      <td>28</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>Madhouse</td>\n",
       "      <td>['Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>24</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>327897</td>\n",
       "      <td>34885</td>\n",
       "      <td>Sep 29, 2023 to Mar 22, 2024</td>\n",
       "      <td>Manga</td>\n",
       "      <td>260976</td>\n",
       "      <td>231570</td>\n",
       "      <td>9258</td>\n",
       "      <td>6146</td>\n",
       "      <td>157424</td>\n",
       "      <td>665374</td>\n",
       "      <td>198138</td>\n",
       "      <td>78513</td>\n",
       "      <td>31030</td>\n",
       "      <td>9605</td>\n",
       "      <td>3152</td>\n",
       "      <td>1708</td>\n",
       "      <td>718</td>\n",
       "      <td>426</td>\n",
       "      <td>401</td>\n",
       "      <td>4071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_english               name  score  ranked  \\\n",
       "0  Frieren: Beyond Journey's End  Sousou no Frieren   9.39       1   \n",
       "\n",
       "   popularity  members                                           synopsis  \\\n",
       "0         304   665374  During their decade-long quest to defeat the D...   \n",
       "\n",
       "                 synonyms type_of  total_episodes  premiered   studios  \\\n",
       "0  Frieren at the Funeral      TV              28  Fall 2023  Madhouse   \n",
       "\n",
       "                              genres demographic  duration_per_ep  \\\n",
       "0  ['Adventure', 'Drama', 'Fantasy']     Shounen               24   \n",
       "\n",
       "                      rating  scored_by  favorites  \\\n",
       "0  PG-13 - Teens 13 or older     327897      34885   \n",
       "\n",
       "                          aired source  watching  completed  on_hold  dropped  \\\n",
       "0  Sep 29, 2023 to Mar 22, 2024  Manga    260976     231570     9258     6146   \n",
       "\n",
       "   plan_to_watch   total  scored_10_by  scored_9_by  scored_8_by  scored_7_by  \\\n",
       "0         157424  665374        198138        78513        31030         9605   \n",
       "\n",
       "   scored_6_by  scored_5_by  scored_4_by  scored_3_by  scored_2_by  \\\n",
       "0         3152         1708          718          426          401   \n",
       "\n",
       "   scored_1_by  \n",
       "0         4071  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2249 entries, 0 to 2248\n",
      "Data columns (total 36 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   name_english     2249 non-null   object \n",
      " 1   name             2249 non-null   object \n",
      " 2   score            2249 non-null   float64\n",
      " 3   ranked           2249 non-null   int64  \n",
      " 4   popularity       2249 non-null   int64  \n",
      " 5   members          2249 non-null   int64  \n",
      " 6   synopsis         2249 non-null   object \n",
      " 7   synonyms         2249 non-null   object \n",
      " 8   type_of          2249 non-null   object \n",
      " 9   total_episodes   2249 non-null   int64  \n",
      " 10  premiered        2249 non-null   object \n",
      " 11  studios          2249 non-null   object \n",
      " 12  genres           1716 non-null   object \n",
      " 13  demographic      1086 non-null   object \n",
      " 14  duration_per_ep  2249 non-null   int64  \n",
      " 15  rating           2249 non-null   object \n",
      " 16  scored_by        2249 non-null   int64  \n",
      " 17  favorites        2249 non-null   int64  \n",
      " 18  aired            2249 non-null   object \n",
      " 19  source           2249 non-null   object \n",
      " 20  watching         2249 non-null   int64  \n",
      " 21  completed        2249 non-null   int64  \n",
      " 22  on_hold          2249 non-null   int64  \n",
      " 23  dropped          2249 non-null   int64  \n",
      " 24  plan_to_watch    2249 non-null   int64  \n",
      " 25  total            2249 non-null   int64  \n",
      " 26  scored_10_by     2249 non-null   int64  \n",
      " 27  scored_9_by      2249 non-null   int64  \n",
      " 28  scored_8_by      2249 non-null   int64  \n",
      " 29  scored_7_by      2249 non-null   int64  \n",
      " 30  scored_6_by      2249 non-null   int64  \n",
      " 31  scored_5_by      2249 non-null   int64  \n",
      " 32  scored_4_by      2249 non-null   int64  \n",
      " 33  scored_3_by      2249 non-null   int64  \n",
      " 34  scored_2_by      2249 non-null   int64  \n",
      " 35  scored_1_by      2249 non-null   int64  \n",
      "dtypes: float64(1), int64(23), object(12)\n",
      "memory usage: 632.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['score', 'popularity', 'members', 'duration_per_ep'\n",
    "                              , 'scored_by', 'favorites', 'watching', 'completed', 'on_hold'\n",
    "                              , 'dropped', 'plan_to_watch', 'total', 'scored_1_by', 'scored_2_by'\n",
    "                              ,'scored_3_by','scored_4_by','scored_5_by','scored_6_by','scored_7_by'\n",
    "                              ,'scored_8_by','scored_9_by','scored_10_by', 'total_episodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_columns = scaler.fit_transform(df[columns_to_scale])\n",
    "df[columns_to_scale] = scaled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_english</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>type_of</th>\n",
       "      <th>total_episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>studios</th>\n",
       "      <th>genres</th>\n",
       "      <th>demographic</th>\n",
       "      <th>duration_per_ep</th>\n",
       "      <th>rating</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>favorites</th>\n",
       "      <th>aired</th>\n",
       "      <th>source</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>plan_to_watch</th>\n",
       "      <th>total</th>\n",
       "      <th>scored_10_by</th>\n",
       "      <th>scored_9_by</th>\n",
       "      <th>scored_8_by</th>\n",
       "      <th>scored_7_by</th>\n",
       "      <th>scored_6_by</th>\n",
       "      <th>scored_5_by</th>\n",
       "      <th>scored_4_by</th>\n",
       "      <th>scored_3_by</th>\n",
       "      <th>scored_2_by</th>\n",
       "      <th>scored_1_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frieren: Beyond Journey's End</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.169224</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>Frieren at the Funeral</td>\n",
       "      <td>TV</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>Madhouse</td>\n",
       "      <td>['Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>0.117663</td>\n",
       "      <td>0.154921</td>\n",
       "      <td>Sep 29, 2023 to Mar 22, 2024</td>\n",
       "      <td>Manga</td>\n",
       "      <td>0.15735</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.245724</td>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.19453</td>\n",
       "      <td>0.096408</td>\n",
       "      <td>0.04338</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.02256</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.08047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_english               name  score  ranked  \\\n",
       "0  Frieren: Beyond Journey's End  Sousou no Frieren    1.0       1   \n",
       "\n",
       "   popularity   members                                           synopsis  \\\n",
       "0    0.021421  0.169224  During their decade-long quest to defeat the D...   \n",
       "\n",
       "                 synonyms type_of  total_episodes  premiered   studios  \\\n",
       "0  Frieren at the Funeral      TV        0.015669  Fall 2023  Madhouse   \n",
       "\n",
       "                              genres demographic  duration_per_ep  \\\n",
       "0  ['Adventure', 'Drama', 'Fantasy']     Shounen         0.137725   \n",
       "\n",
       "                      rating  scored_by  favorites  \\\n",
       "0  PG-13 - Teens 13 or older   0.117663   0.154921   \n",
       "\n",
       "                          aired source  watching  completed   on_hold  \\\n",
       "0  Sep 29, 2023 to Mar 22, 2024  Manga   0.15735   0.067216  0.033298   \n",
       "\n",
       "    dropped  plan_to_watch     total  scored_10_by  scored_9_by  scored_8_by  \\\n",
       "0  0.028787       0.245724  0.169224       0.19453     0.096408      0.04338   \n",
       "\n",
       "   scored_7_by  scored_6_by  scored_5_by  scored_4_by  scored_3_by  \\\n",
       "0     0.020112     0.018679      0.02256     0.016262     0.022185   \n",
       "\n",
       "   scored_2_by  scored_1_by  \n",
       "0     0.039492      0.08047  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['type_of', 'studios', 'rating', 'source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie --> 0\n",
      "ONA --> 1\n",
      "OVA --> 2\n",
      "Special --> 3\n",
      "TV --> 4\n",
      "TV Special --> 5\n",
      "G - All Ages --> 0\n",
      "PG - Children --> 1\n",
      "PG-13 - Teens 13 or older --> 2\n",
      "R - 17+ (violence & profanity) --> 3\n",
      "R+ - Mild Nudity --> 4\n",
      "4-koma manga --> 0\n",
      "Book --> 1\n",
      "Card game --> 2\n",
      "Game --> 3\n",
      "Light novel --> 4\n",
      "Manga --> 5\n",
      "Mixed media --> 6\n",
      "Music --> 7\n",
      "Novel --> 8\n",
      "Original --> 9\n",
      "Other --> 10\n",
      "Picture book --> 11\n",
      "Unknown --> 12\n",
      "Visual novel --> 13\n",
      "Web manga --> 14\n",
      "Web novel --> 15\n"
     ]
    }
   ],
   "source": [
    "for column in columns_to_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "    for original_value, encoded_value in zip(label_encoder.classes_,\n",
    "                                             label_encoder.transform(label_encoder.classes_)):\n",
    "        if column != 'studios':\n",
    "            print(f'{original_value} --> {encoded_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['demographic'] = df['demographic'].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_english</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>type_of</th>\n",
       "      <th>total_episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>studios</th>\n",
       "      <th>genres</th>\n",
       "      <th>demographic</th>\n",
       "      <th>duration_per_ep</th>\n",
       "      <th>rating</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>favorites</th>\n",
       "      <th>aired</th>\n",
       "      <th>source</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>plan_to_watch</th>\n",
       "      <th>total</th>\n",
       "      <th>scored_10_by</th>\n",
       "      <th>scored_9_by</th>\n",
       "      <th>scored_8_by</th>\n",
       "      <th>scored_7_by</th>\n",
       "      <th>scored_6_by</th>\n",
       "      <th>scored_5_by</th>\n",
       "      <th>scored_4_by</th>\n",
       "      <th>scored_3_by</th>\n",
       "      <th>scored_2_by</th>\n",
       "      <th>scored_1_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frieren: Beyond Journey's End</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.169224</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>Frieren at the Funeral</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>99</td>\n",
       "      <td>['Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>[Shounen]</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117663</td>\n",
       "      <td>0.154921</td>\n",
       "      <td>Sep 29, 2023 to Mar 22, 2024</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15735</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.245724</td>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.19453</td>\n",
       "      <td>0.096408</td>\n",
       "      <td>0.04338</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.02256</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.08047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_english               name  score  ranked  \\\n",
       "0  Frieren: Beyond Journey's End  Sousou no Frieren    1.0       1   \n",
       "\n",
       "   popularity   members                                           synopsis  \\\n",
       "0    0.021421  0.169224  During their decade-long quest to defeat the D...   \n",
       "\n",
       "                 synonyms  type_of  total_episodes  premiered  studios  \\\n",
       "0  Frieren at the Funeral        4        0.015669  Fall 2023       99   \n",
       "\n",
       "                              genres demographic  duration_per_ep  rating  \\\n",
       "0  ['Adventure', 'Drama', 'Fantasy']   [Shounen]         0.137725       2   \n",
       "\n",
       "   scored_by  favorites                         aired  source  watching  \\\n",
       "0   0.117663   0.154921  Sep 29, 2023 to Mar 22, 2024       5   0.15735   \n",
       "\n",
       "   completed   on_hold   dropped  plan_to_watch     total  scored_10_by  \\\n",
       "0   0.067216  0.033298  0.028787       0.245724  0.169224       0.19453   \n",
       "\n",
       "   scored_9_by  scored_8_by  scored_7_by  scored_6_by  scored_5_by  \\\n",
       "0     0.096408      0.04338     0.020112     0.018679      0.02256   \n",
       "\n",
       "   scored_4_by  scored_3_by  scored_2_by  scored_1_by  \n",
       "0     0.016262     0.022185     0.039492      0.08047  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Action', 'Adventure', 'Drama', 'Fantasy']\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['genres'][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_genres(x):\n",
    "    if type(x) != float:\n",
    "        return ', '.join(ast.literal_eval(x))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(convert_to_list_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_demographic(x):\n",
    "    if not any(pd.isna(a) for a in x):\n",
    "        return ', ' + ''.join(x)\n",
    "    else:\n",
    "        return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['demographic'] = df['demographic'].apply(convert_to_list_demographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].fillna('')\n",
    "df['demographic'] = df['demographic'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_string'] = df['synopsis'] + df['genres'] + df['demographic'] + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['input_string'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub('[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def train_word2vec_model(texts):\n",
    "    # Initialize Word2Vec model\n",
    "    model = Word2Vec(sentences=texts, vector_size=100, window=5, min_count=1, workers=8)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_text_vector(processed_text, model):\n",
    "    # Initialize an empty vector\n",
    "    text_vector = np.zeros((model.vector_size,), dtype=\"float32\")\n",
    "    \n",
    "    # Iterate over each word in the processed text\n",
    "    for word in processed_text:\n",
    "        # Check if the word is in the vocabulary of the Word2Vec model\n",
    "        if word in model.wv.key_to_index:\n",
    "            # Get the word vector from the model and add it to the text vector\n",
    "            text_vector = np.add(text_vector, model.wv[word])\n",
    "    \n",
    "    # Calculate the mean of all word vectors to get the text vector\n",
    "    text_vector = text_vector / len(processed_text)\n",
    "    \n",
    "    return text_vector\n",
    "\n",
    "def process_text_and_get_vector(text):\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Train Word2Vec model\n",
    "    model = train_word2vec_model([processed_text])\n",
    "    \n",
    "    # Get vector for input text\n",
    "    text_vector = get_text_vector(processed_text, model)\n",
    "    \n",
    "    return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector_rep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msynopsis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_text_and_get_vector\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[47], line 52\u001b[0m, in \u001b[0;36mprocess_text_and_get_vector\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     49\u001b[0m processed_text \u001b[38;5;241m=\u001b[39m preprocess_text(text)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Train Word2Vec model\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_word2vec_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprocessed_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Get vector for input text\u001b[39;00m\n\u001b[0;32m     55\u001b[0m text_vector \u001b[38;5;241m=\u001b[39m get_text_vector(processed_text, model)\n",
      "Cell \u001b[1;32mIn[47], line 27\u001b[0m, in \u001b[0;36mtrain_word2vec_model\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_word2vec_model\u001b[39m(texts):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Initialize Word2Vec model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:1045\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha \u001b[38;5;241m=\u001b[39m end_alpha \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m-> 1045\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_training_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     ),\n\u001b[0;32m   1055\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\22213\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:1543\u001b[0m, in \u001b[0;36mWord2Vec._check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1540\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEffective \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m higher than previous training cycles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mkey_to_index:  \u001b[38;5;66;03m# should be set by `build_vocab`\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must first build vocabulary before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors):\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must initialize vectors before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "df['vector_rep'] = df['synopsis'].apply(process_text_and_get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
